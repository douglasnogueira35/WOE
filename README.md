# ğŸ“Š Projeto Final - Credit Scoring com Machine Learning

Este projeto demonstra como aplicar **Machine Learning** para prever **bons e maus pagadores** em uma base de crÃ©dito.  
O trabalho foi desenvolvido em **Python** com bibliotecas como **Scikit-Learn, LightGBM, XGBoost e Streamlit**, e inclui anÃ¡lise exploratÃ³ria, comparaÃ§Ã£o de modelos e implementaÃ§Ã£o de um app interativo.

---

## ğŸš€ Objetivos
- Construir um pipeline completo de prÃ©-processamento e modelagem.
- Comparar diferentes algoritmos de regressÃ£o/classificaÃ§Ã£o.
- Escolher o modelo com melhor desempenho para escoragem.
- Implementar uma interface em **Streamlit** para uso prÃ¡tico.
- Gerar insights de negÃ³cio a partir das variÃ¡veis mais relevantes.

---

## ğŸ§¾ Modelos testados
- **RegressÃ£o Linear**
- **Random Forest Regressor**
- **XGBRegressor**
- **LightGBM (modelo final)**

ğŸ“Œ O modelo que mais se destacou foi **Random Forest Regressor**, mas o **LightGBM** foi escolhido para produÃ§Ã£o por sua eficiÃªncia e boa performance.

---

## ğŸ“– ExplicaÃ§Ãµes e Insights

### Por que este modelo?
- **Random Forest** apresentou melhor desempenho geral.  
- **LightGBM** foi utilizado para escoragem final pela rapidez e capacidade de lidar com grandes volumes de dados.  
- **XGBoost** mostrou potencial para identificar padrÃµes ocultos, mas com maior custo computacional.

### Insights de NegÃ³cio
- O modelo ajuda a identificar perfis de maior risco de inadimplÃªncia.  
- VariÃ¡veis como **tipo_renda**, **idade** e **posse_de_imÃ³vel** tiveram grande importÃ¢ncia.  
- Clientes com renda instÃ¡vel ou sem patrimÃ´nio apresentaram maior score de inadimplÃªncia.  
- EstratÃ©gias de crÃ©dito podem ser ajustadas com base nesses resultados.

---

## ğŸ“Š GrÃ¡ficos Comparativos
- ImportÃ¢ncia das variÃ¡veis  
- DistribuiÃ§Ã£o dos scores por **tipo_renda**  
- Curva ROC e mÃ©tricas (AUC, KS, Gini)

*(insira imagens ou links dos grÃ¡ficos aqui)*

---

## ğŸ–¥ï¸ AplicaÃ§Ã£o em Streamlit
O app permite:
1. Upload de arquivos CSV.  
2. Escoragem automÃ¡tica com o modelo treinado (`model_final.pkl`).  
3. VisualizaÃ§Ã£o dos scores de inadimplÃªncia.  
4. Download da base escorada.  

### Rodando localmente
```bash
pip install -r requirements.txt
streamlit run app.py
